{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 6] The handle is invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9601181500b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;31m## produce a video that finds objects ########\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;31m#videoAnnotate(\"test_videos/MOVI0017.avi\", \"test_videos/MOVI0017SSD.mp4\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m \u001b[0mvideoAnnotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_videos/MOVI0018.avi\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test_videos/MOVI0018SSD.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;31m#videoAnnotate(\"test_videos/MOVI0019.avi\", \"test_videos/MOVI0019SSD.mp4\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;31m#videoAnnotate(\"test_videos/MOVI0019_69to79sec.mp4\", \"test_videos/MOVI0019_69to79secSSD.mp4\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-9601181500b2>\u001b[0m in \u001b[0;36mvideoAnnotate\u001b[1;34m(VideoIn, VideoOut)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;33m<\u001b[0m\u001b[0msource\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"{0}\"\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \"\"\".format(SSDobjDet(VideoIn, VideoOut)\n\u001b[0m\u001b[0;32m    300\u001b[0m         ))  \n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-9601181500b2>\u001b[0m in \u001b[0;36mSSDobjDet\u001b[1;34m(Vin, Vout)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mSSDobjDet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     \u001b[0mclip1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[0mwhite_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time white_clip.write_videofile(Vout, audio=False)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[0;32m     79\u001b[0m                                          \u001b[0mtarget_resolution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_resolution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                                          \u001b[0mresize_algo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresize_algorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                                          fps_source=fps_source)\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# Make some of the reader's attributes accessible from the clip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[1;32m---> 32\u001b[1;33m                                    fps_source)\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'video_fps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'video_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py\u001b[0m in \u001b[0;36mffmpeg_parse_infos\u001b[1;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mpopen_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"creationflags\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0x08000000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpopen_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    592\u001b[0m                  pass_fds=(), *, encoding=None, errors=None):\n\u001b[0;32m    593\u001b[0m         \u001b[1;34m\"\"\"Create new Popen instance.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Held while anything is calling waitpid before returncode has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# updated to prevent clobbering returncode if wait() or poll() are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_cleanup\u001b[1;34m()\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_active\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_deadstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_internal_poll\u001b[1;34m(self, _deadstate, _WaitForSingleObject, _WAIT_OBJECT_0, _GetExitCodeProcess)\u001b[0m\n\u001b[0;32m   1025\u001b[0m             \"\"\"\n\u001b[0;32m   1026\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0m_WaitForSingleObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_WAIT_OBJECT_0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1028\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_GetExitCodeProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 6] The handle is invalid"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "# In[ ]:\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import time \n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# This is needed to display the images.\n",
    "#get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "######from my Udacity capstone project#######\n",
    "\n",
    "def traffic_light_location(boxes, scores, classes, img_size=[600, 800, 3], score_thresh=0.2):\n",
    "    # tensorflow usually operates on a set of images \n",
    "    boxes = boxes[0]\n",
    "    scores = scores[0]\n",
    "    classes = classes[0]\n",
    "    #for i in range(len(scores)):\n",
    "     #   print(\"testing scores[{}]: {}\".format(i, scores[i])) \n",
    "      #  print(\"tesing  classes[{}]: {}\".format(i, classes[i]))   \n",
    "    output_boxes = []\n",
    "    # For now only do box around highest score. NOT ROBUST.\n",
    "    for i in range(len(scores)):\n",
    "        # Must be a traffic light and meet threshold.\n",
    "        #classes = 10 means is a traffic light\n",
    "        if scores[i] > score_thresh and classes[i] == 10:\n",
    "            #print(\"traffic light detected.  scores[{}]: {}, classes: {}, boxes: {}\".format(i, scores[i], classes[i], boxes[i]))\n",
    "            # Box values are between 0-1.\n",
    "            left_x = int(boxes[i][1]*img_size[1])\n",
    "            top_y = int(boxes[i][0]*img_size[0])\n",
    "            right_x = int(boxes[i][3]*img_size[1])\n",
    "            bot_y = int(boxes[i][2]*img_size[0])\n",
    "            output_boxes.append([left_x, top_y, right_x, bot_y])\n",
    "            break\n",
    "    return output_boxes\n",
    "###############################################\n",
    "def get_light_color(img, tl_box, lower_HSV, upper_HSV):\n",
    "    # retain the orignal image\n",
    "    imgOrig = img\n",
    "    \n",
    "    #convert rgb to bgr\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    colorID = \"UNKNOWN\"\n",
    "    # median blur the image\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    # Convert image to HSV\n",
    "    hsvImg = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "    # Threshold the HSV image to get only selected(red, green, or yellow) colors\n",
    "    mask = cv2.inRange(hsvImg, lower_HSV, upper_HSV) \n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(img,img, mask= mask)\n",
    "\n",
    "    #mask out the area in image that has no traffic lights\n",
    "    #create a black image\n",
    "    polygon_img = np.zeros(img.shape, np.uint8)\n",
    "      \n",
    "    #draw a polygon\n",
    "    left_x = tl_box[0]\n",
    "    top_y = tl_box[1]\n",
    "    right_x = tl_box[2]\n",
    "    bot_y = tl_box[3]\n",
    "    #print(\"left_x: {}, top_y:  {}, right_x: {}, bot_y: {}\".format(left_x, top_y, right_x, bot_y))\n",
    "    pts = np.array([[left_x, top_y], [right_x, top_y], [right_x, bot_y], [left_x, bot_y]])\n",
    "    cv2.fillPoly(polygon_img, pts=[pts], color=(255,255,255))\n",
    "    res = cv2.bitwise_and(res,res,mask=polygon_img[:,:,1])\n",
    "        \n",
    "    # Debug.\n",
    "    #cv2.imwrite('img.png',img)\n",
    "    #cv2.imwrite('poly.png',polygon_img)\n",
    "\n",
    "    #cv2.imwrite('combined.jpg',cv2.bitwise_and(\n",
    "        #img,img,mask=polygon_img[:,:,1]))\n",
    "    g=res\n",
    "    #brightest spot\n",
    "    a = np.array(g)\n",
    "    #print(a.max(), np.unravel_index(a.argmax(), a.shape))\n",
    "    brighty = np.unravel_index(a.argmax(), a.shape)[0]\n",
    "    brightx = np.unravel_index(a.argmax(), a.shape)[1]\n",
    "    #print(\"Brightest spot, brightx: {}, birghty: {}\".format(brightx, brighty)) \n",
    "\n",
    "    #color hsv range boolean\n",
    "    greenColor = np.all(lower_HSV == np.array([60, 125, 125])) and np.all(upper_HSV == np.array([120,255,255]))\n",
    "    redColor = np.all(lower_HSV == np.array([170, 125, 125])) and np.all(upper_HSV == np.array([179,255,255]))\n",
    "    yellowColor = np.all(lower_HSV == np.array([5, 150, 150])) and np.all(upper_HSV == np.array([40,255,255]))\n",
    "\n",
    "    #divide the bounding box into 3 regions: red, yellow, and green\n",
    "    upperYellowy = top_y + (bot_y - top_y)/3\n",
    "    lowerYellowy = bot_y - (bot_y - top_y)/3\n",
    "    #print(\"top_y: {}, upperYellowy: {}, lowerYellowy: {}, bot_y:{}\".format(top_y, upperYellowy, lowerYellowy, bot_y))\n",
    "    #put the original image back\n",
    "    img = imgOrig\n",
    "    \n",
    "    if (((brightx == 0) and (brighty == 0)) == False):\n",
    "        if (brighty >= lowerYellowy and brighty <= bot_y) and (greenColor == True):\n",
    "            #print(\"********* G R E E N *********\")\n",
    "            cv2.rectangle(img, (brightx -15, brighty - 15), (brightx + 15, brighty + 15), (0,255,0),2)\n",
    "            cv2.putText(img, \"green traffic light\", (brightx-15, brighty -27), 0, 1.2, (0,255,0),2)\n",
    "            colorID = \"GREEN\"\n",
    "            #print(\"At time: {} sec, colorID: TrafficLight.GREEN \".format(str(time.clock())))\n",
    "        elif (brighty >= top_y and brighty < upperYellowy) and (redColor == True):\n",
    "            #print(\"*********   R E D   *********\")\n",
    "            cv2.rectangle(img, (brightx -15, brighty - 15), (brightx + 15, brighty + 15), (0,0,255),2)\n",
    "            cv2.putText(img, \"red traffic light\", (brightx-15, brighty -27), 0, 1.2, (0,0,255),2)\n",
    "            colorID = \"RED\"\n",
    "            #print(\"At time: {} sec, colorID: TrafficLight.RED\".format(str(time.clock())))\n",
    "        elif (brighty >= upperYellowy and brighty < lowerYellowy) and (yellowColor == True):\n",
    "            #print(\"******** Y E L L O W ********\")\n",
    "            cv2.rectangle(img, (brightx -15, brighty - 15), (brightx + 15, brighty + 15), (255,255,0),2)\n",
    "            cv2.putText(img, \"yellow traffic light\", (brightx-15, brighty -27), 0, 1.2, (255,255,0),2)\n",
    "              \n",
    "            colorID = \"YELLOW\"\n",
    "            #print(\"At time: {} sec, colorID: TrafficLight.YELLOW\".format(str(time.clock())))\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "    return colorID, img\n",
    "\n",
    "    \n",
    "#############################################        \n",
    "\n",
    "#############################################\n",
    "def loadSSD():\n",
    "    #load classifier\n",
    "    MODEl_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "    PATH_TO_MODEL = 'frozen_inference_graph.pb'\n",
    "    detection_graph = tf.Graph()\n",
    "\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "\n",
    "        with tf.gfile.GFile(\"/\".join([MODEl_NAME,PATH_TO_MODEL]), 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    return detection_graph\n",
    "#do a SSD image processing function##############\n",
    "def process_image(image):\n",
    "    #convert BGR to RGB\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # List of the strings that is used to add correct label for each box.\n",
    "    PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "    NUM_CLASSES = 90\n",
    "\n",
    "    #Loading label map\n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "    categories =      label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index =     label_map_util.create_category_index(categories)\n",
    "    \n",
    "    # Definite input and output Tensors for detection_graph\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image, axis=0)\n",
    "    # Actual detection.\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "                  [detection_boxes, \n",
    "                   detection_scores, \n",
    "                   detection_classes, \n",
    "                   num_detections],\n",
    "            feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                 image,\n",
    "                 np.squeeze(boxes),\n",
    "                 np.squeeze(classes).astype(np.int32),\n",
    "                 np.squeeze(scores),\n",
    "                 category_index,\n",
    "                 use_normalized_coordinates=True,\n",
    "                 line_thickness=8)\n",
    "           #print(\"Tensorflow image process: boxes: {}\".format(boxes))\n",
    "           #print(\"scores: {}\".format(scores))\n",
    "           #print(\"classes: {}\".format(classes))\n",
    "           #print(\"num: {}\".format(num))\n",
    "\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "\n",
    "    ##from my code in Udacity CapstoneProject for traffic light color classification########\n",
    "    #initialize all variables\n",
    "    yellowLight = False\n",
    "    redLight = False\n",
    "    greenLight = False\n",
    "    yellowImg = image\n",
    "    redImg = image\n",
    "    greenImg = image\n",
    "    result = image\n",
    "\n",
    "    #The size of one traffic light is about 50 in x direction,125 in y direction\n",
    "    #The center of the image is:\n",
    "    x = image.shape[1]/2 \n",
    "    y = image.shape[0]/2 \n",
    "\n",
    "    tl_loc = traffic_light_location(boxes, scores, classes, image.shape)\n",
    "    #print(tl_loc[0])\n",
    "    # No traffic lights found, look in Bernards original location.\n",
    "    if len(tl_loc) == 0:\n",
    "        tl_loc = 0 #print(\"No Lights found by NN!\")\n",
    "    else:\n",
    "        \n",
    "        ###################green color detection##########\n",
    "        # define range of green color in HSV\n",
    "        lower_green = np.array([60,125,125]) #100,100])\n",
    "        upper_green = np.array([120,255,255])\n",
    "        [clr_ID, greenImg] = get_light_color(image, tl_loc[0], lower_green, upper_green)\n",
    "        if (clr_ID == \"GREEN\"):\n",
    "            greenLight = True\n",
    "        ##################red color detection#################\n",
    "        # define range of red color in HSV\n",
    "        lower_red = np.array([170,125,125]) \n",
    "        upper_red = np.array([179,255,255])\n",
    "        [clr_ID, redImg] = get_light_color(image, tl_loc[0], lower_red, upper_red)\n",
    "        if (clr_ID == \"RED\"):\n",
    "            redLight = True\n",
    "\n",
    "\n",
    "        ###########yellow traffic light detection###########\n",
    "        # define range of orange color in HSV\n",
    "        lower_yellow = np.array([5,150,150]) \n",
    "        upper_yellow = np.array([40,255,255]) #real amber traffic light works 15,255,255])\n",
    "        [clr_ID, yellowImg] = get_light_color(image, tl_loc[0], lower_yellow, upper_yellow)\n",
    "        if (clr_ID == \"YELLOW\"):\n",
    "            yellowLight = True\n",
    "\t\n",
    "        if ((yellowLight == True) and (redLight == False) \n",
    "             and (greenLight == False)):\n",
    "            clr_ID = \"YELLOW\"\n",
    "            result = yellowImg\n",
    "\n",
    "        elif ((yellowLight == False) and (redLight == True) \n",
    "            and (yellowLight == False)):\n",
    "            clr_ID = \"RED\"\n",
    "            result = redImg\n",
    "\n",
    "        elif ((yellowLight == False) and (redLight == False) \n",
    "             and (greenLight == True)):\n",
    "            clr_ID = \"GREEN\" \n",
    "            result = greenImg\n",
    "        else:\n",
    "            clr_ID = \"UNKNOWN\"\n",
    "            result = image\n",
    "        \n",
    "        #plt.imshow(result)\n",
    "        #plt.show()\n",
    "        #print(\"Traffic Light color_ID: {}\".format(clr_ID))\n",
    "    return result        \n",
    "\n",
    "def SSDobjDet(Vin, Vout):\n",
    "    clip1 = VideoFileClip(Vin)\n",
    "    white_clip = clip1.fl_image(process_image)\n",
    "    %time white_clip.write_videofile(Vout, audio=False)\n",
    "    return Vout\n",
    "\n",
    "def videoAnnotate(VideoIn, VideoOut):\n",
    "    HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "    <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(SSDobjDet(VideoIn, VideoOut)\n",
    "        ))  \n",
    "            \n",
    "####main run######\n",
    "#load the SSD classifier\n",
    "global detection_graph\n",
    "detection_graph = loadSSD()\n",
    "\n",
    "\"\"\"\n",
    "dir = \"test_images/image\" \n",
    "for i in range(13,16):\n",
    "    FNum = \"\".join([dir, str(i+1)])\n",
    "    FName = \".\".join([FNum, \"jpg\"])\n",
    "    print(\"File name: {}\".format(FName))\n",
    "    plt.imshow(process_image(cv2.cvtColor(cv2.imread(FName), cv2.COLOR_BGR2RGB)))\n",
    "    plt.show()\n",
    "\"\"\" \n",
    "## produce a video that finds objects ########\n",
    "#videoAnnotate(\"test_videos/MOVI0017.avi\", \"test_videos/MOVI0017SSD.mp4\")\n",
    "videoAnnotate(\"test_videos/MOVI0018.avi\", \"test_videos/MOVI0018SSD.mp4\")\n",
    "#videoAnnotate(\"test_videos/MOVI0019.avi\", \"test_videos/MOVI0019SSD.mp4\")\n",
    "#videoAnnotate(\"test_videos/MOVI0019_69to79sec.mp4\", \"test_videos/MOVI0019_69to79secSSD.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
