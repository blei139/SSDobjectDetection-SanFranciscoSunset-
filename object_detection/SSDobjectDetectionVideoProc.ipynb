{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SSD classifier.\n",
      "[MoviePy] >>>> Building video test_videos/MOVI0017SSD_1min32secto3min2sec.mp4\n",
      "[MoviePy] Writing video test_videos/MOVI0017SSD_1min32secto3min2sec.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1615/1615 [2:03:06<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos/MOVI0017SSD_1min32secto3min2sec.mp4 \n",
      "\n",
      "Wall time: 2h 3min 7s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "# In[ ]:\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import time \n",
    "import copy\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# This is needed to display the images.\n",
    "#get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "######from my Udacity capstone project#######\n",
    "\n",
    "def traffic_light_location(boxes, scores, classes, img_size=[600, 800, 3], score_thresh=0.2):\n",
    "    # tensorflow usually operates on a set of images \n",
    "    boxes = boxes[0]\n",
    "    scores = scores[0]\n",
    "    classes = classes[0]\n",
    "    #for i in range(len(scores)):\n",
    "     #   print(\"testing scores[{}]: {}\".format(i, scores[i])) \n",
    "      #  print(\"tesing  classes[{}]: {}\".format(i, classes[i]))   \n",
    "    output_boxes = []\n",
    "    # For now only do box around highest score. NOT ROBUST.\n",
    "    for i in range(len(scores)):\n",
    "        # Must be a traffic light and meet threshold.\n",
    "        #classes = 10 means is a traffic light\n",
    "        if scores[i] > score_thresh and classes[i] == 10:\n",
    "            #print(\"traffic light detected.  scores[{}]: {}, classes: {}, boxes: {}\".format(i, scores[i], classes[i], boxes[i]))\n",
    "            # Box values are between 0-1.\n",
    "            left_x = int(boxes[i][1]*img_size[1])\n",
    "            top_y = int(boxes[i][0]*img_size[0])\n",
    "            right_x = int(boxes[i][3]*img_size[1])\n",
    "            bot_y = int(boxes[i][2]*img_size[0])\n",
    "            output_boxes.append([left_x, top_y, right_x, bot_y])\n",
    "            \n",
    "    #print(\"output_boxes: {}\".format(output_boxes))\n",
    "    \n",
    "    return output_boxes\n",
    "###############################################\n",
    "def get_light_color(imgbox, imgo, tl_box, lower_HSV, upper_HSV):\n",
    "    # retain the orignal image\n",
    "    imgOrig = imgbox\n",
    "    \n",
    "    # use initial image without any bounding boxes to classify traffic light\n",
    "    # color since the bounding boxes sometimes totally blocking the traffic light color\n",
    "    img = imgo\n",
    "    \n",
    "    #convert rgb to bgr\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    colorID = \"UNKNOWN\"\n",
    "    # median blur the image\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    # Convert image to HSV\n",
    "    hsvImg = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "    # Threshold the HSV image to get only selected(red, green, or yellow) colors\n",
    "    mask = cv2.inRange(hsvImg, lower_HSV, upper_HSV) \n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(img,img, mask= mask)\n",
    "    \n",
    "    #mask out the area in image that has no traffic lights\n",
    "    #create a black image\n",
    "    polygon_img = np.zeros(img.shape, np.uint8)\n",
    "    \n",
    "    for j in range(len(tl_box)):\n",
    "        #draw a polygon\n",
    "        left_x = tl_box[j][0]\n",
    "        top_y = tl_box[j][1]\n",
    "        right_x = tl_box[j][2]\n",
    "        bot_y = tl_box[j][3]\n",
    "        #print(\"At index: {}, left_x: {}, top_y:  {}, right_x: {}, bot_y: {}\".format(j, left_x, top_y, right_x, bot_y))\n",
    "        pts = np.array([[left_x, top_y], [right_x, top_y], [right_x, bot_y], [left_x, bot_y]])\n",
    "        cv2.fillPoly(polygon_img, pts=[pts], color=(255,255,255))\n",
    "        res1 = cv2.bitwise_and(res,res,mask=polygon_img[:,:,1])\n",
    "        \n",
    "        \n",
    "        # Debug.\n",
    "        #cv2.imwrite('img.png',img)\n",
    "        #cv2.imwrite('poly.png',polygon_img)\n",
    "\n",
    "        #cv2.imwrite('combined.jpg',cv2.bitwise_and(\n",
    "            #img,img,mask=polygon_img[:,:,1]))\n",
    "        \n",
    "        #brightest spot\n",
    "        a = np.array(res1)\n",
    "        #print(a.max(), np.unravel_index(a.argmax(), a.shape))\n",
    "        brighty = np.unravel_index(a.argmax(), a.shape)[0]\n",
    "        brightx = np.unravel_index(a.argmax(), a.shape)[1]\n",
    "        #print(\"Brightest spot, brightx: {}, birghty: {}\".format(brightx, brighty)) \n",
    "\n",
    "        #color hsv range boolean\n",
    "        greenColor = np.all(lower_HSV == np.array([60, 125, 125])) and np.all(upper_HSV == np.array([120,255,255]))\n",
    "        redColor = np.all(lower_HSV == np.array([170, 125, 125])) and np.all(upper_HSV == np.array([179,255,255]))\n",
    "        yellowColor = np.all(lower_HSV == np.array([5, 150, 150])) and np.all(upper_HSV == np.array([40,255,255]))\n",
    "\n",
    "        #divide the bounding box into 3 regions: red, yellow, and green\n",
    "        upperYellowy = top_y + (bot_y - top_y)/3\n",
    "        lowerYellowy = bot_y - (bot_y - top_y)/3\n",
    "        #print(\"Average height of traffic light: {}\".format((bot_y - top_y)/3))\n",
    "        #print(\"Width of the traffic light: {}\".format(right_x - left_x))\n",
    "        #print(\"Ratio of average height over width: {}\".format((bot_y - top_y)/(3*(right_x - left_x))))\n",
    "        avgHWratio = (bot_y - top_y)/(3*(right_x - left_x))\n",
    "        #print(\"top_y: {}, upperYellowy: {}, lowerYellowy: {}, bot_y:{}\".format(top_y, upperYellowy, lowerYellowy, bot_y))\n",
    "        #put the original image back\n",
    "        img = imgOrig\n",
    "        \n",
    "        #average height of the traffic light has to be over 10 pixels for red, yellow, and green 3 color box type\n",
    "        if (((brightx == 0) and (brighty == 0)) == False and avgHWratio > 0.5): #(bot_y - top_y)/3 > 10):\n",
    "            if (brighty >= lowerYellowy and brighty <= bot_y) and (greenColor == True):\n",
    "                #print(\"********* G R E E N *********\")\n",
    "                cv2.rectangle(img, (brightx -15, brighty - 15), (brightx + 15, brighty + 15), (0,255,0),2)\n",
    "                cv2.putText(img, \"green traffic light\", (brightx-15, brighty -27), 0, 1.2, (0,255,0),2)\n",
    "                colorID = \"GREEN\"\n",
    "                #print(\"At time: {} sec, colorID: TrafficLight.GREEN \".format(str(time.clock())))\n",
    "            elif (brighty >= top_y and brighty < upperYellowy) and (redColor == True):\n",
    "                #print(\"*********   R E D   *********\")\n",
    "                cv2.rectangle(img, (brightx -15, brighty - 15), (brightx + 15, brighty + 15), (0,0,255),2)\n",
    "                cv2.putText(img, \"red traffic light\", (brightx-15, brighty -27), 0, 1.2, (0,0,255),2)\n",
    "                colorID = \"RED\"\n",
    "               #print(\"At time: {} sec, colorID: TrafficLight.RED\".format(str(time.clock())))\n",
    "            elif (brighty >= upperYellowy and brighty < lowerYellowy) and (yellowColor == True):\n",
    "                #print(\"******** Y E L L O W ********\")\n",
    "                cv2.rectangle(img, (brightx -15, brighty - 15), (brightx + 15, brighty + 15), (255,255,0),2)\n",
    "                cv2.putText(img, \"yellow traffic light\", (brightx-15, brighty -27), 0, 1.2, (255,255,0),2)\n",
    "              \n",
    "                colorID = \"YELLOW\"\n",
    "               #print(\"At time: {} sec, colorID: TrafficLight.YELLOW\".format(str(time.clock())))\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "    return colorID, img\n",
    "\n",
    "    \n",
    "## ###########################################        \n",
    "def download_frozen_model():\n",
    "    print(\"Downloading frozen model.\")\n",
    "    MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "    MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "    DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "    # Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "    PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "    # List of the strings that is used to add correct label for each box.\n",
    "    PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "    NUM_CLASSES = 90\n",
    "\n",
    "\n",
    "# ## Download Model\n",
    "\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "    tar_file = tarfile.open(MODEL_FILE)\n",
    "    for file in tar_file.getmembers():\n",
    "       file_name = os.path.basename(file.name)\n",
    "       if 'frozen_inference_graph.pb' in file_name:\n",
    "          tar_file.extract(file, os.getcwd())\n",
    "\n",
    "#############################################\n",
    "def loadSSD():\n",
    "    #load classifier\n",
    "    MODEl_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "    PATH_TO_MODEL = 'frozen_inference_graph.pb'\n",
    "    detection_graph = tf.Graph()\n",
    "\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "\n",
    "        with tf.gfile.GFile(\"/\".join([MODEl_NAME,PATH_TO_MODEL]), 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "    return detection_graph\n",
    "#do a SSD image processing function##############\n",
    "def process_image(image):\n",
    "    #Retain the initial image before ssd bounding boxes are drawn.\n",
    "    #create a deep copy \n",
    "    imgo = copy.deepcopy(image)\n",
    "    \n",
    "    # List of the strings that is used to add correct label for each box.\n",
    "    PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "    NUM_CLASSES = 90\n",
    "\n",
    "    #Loading label map\n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "    categories =      label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index =     label_map_util.create_category_index(categories)\n",
    "    \n",
    "    # Definite input and output Tensors for detection_graph\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image, axis=0)\n",
    "    # Actual detection.\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "                  [detection_boxes, \n",
    "                   detection_scores, \n",
    "                   detection_classes, \n",
    "                   num_detections],\n",
    "            feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                 image,\n",
    "                 np.squeeze(boxes),\n",
    "                 np.squeeze(classes).astype(np.int32),\n",
    "                 np.squeeze(scores),\n",
    "                 category_index,\n",
    "                 use_normalized_coordinates=True,\n",
    "                 line_thickness=8)\n",
    "           #print(\"Tensorflow image process: boxes: {}\".format(boxes))\n",
    "           #print(\"scores: {}\".format(scores))\n",
    "           #print(\"classes: {}\".format(classes))\n",
    "           #print(\"num: {}\".format(num))\n",
    "\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "    \n",
    "    ##from my code in Udacity CapstoneProject for traffic light color classification########\n",
    "    #initialize all variables\n",
    "    yellowLight = False\n",
    "    redLight = False\n",
    "    greenLight = False\n",
    "    yellowImg = image\n",
    "    redImg = image\n",
    "    greenImg = image\n",
    "    result = image\n",
    "\n",
    "    #The size of one traffic light is about 50 in x direction,125 in y direction\n",
    "    #The center of the image is:\n",
    "    x = image.shape[1]/2 \n",
    "    y = image.shape[0]/2 \n",
    "\n",
    "    tl_loc = traffic_light_location(boxes, scores, classes, image.shape)\n",
    "    #print(tl_loc)\n",
    "    # No traffic lights found, look in Bernards original location.\n",
    "    if len(tl_loc) == 0:\n",
    "        tl_loc = 0 #print(\"No Lights found by NN!\")\n",
    "    else:     \n",
    "        ###################green color detection##########\n",
    "        # define range of green color in HSV\n",
    "        lower_green = np.array([60,125,125]) #100,100])\n",
    "        upper_green = np.array([120,255,255])\n",
    "        [clr_ID, greenImg] = get_light_color(image, imgo, tl_loc, lower_green, upper_green)\n",
    "        if (clr_ID == \"GREEN\"):\n",
    "            greenLight = True\n",
    "        ##################red color detection#################\n",
    "        # define range of red color in HSV\n",
    "        lower_red = np.array([170,125,125]) \n",
    "        upper_red = np.array([179,255,255])\n",
    "        [clr_ID, redImg] = get_light_color(image, imgo, tl_loc, lower_red, upper_red)\n",
    "        if (clr_ID == \"RED\"):\n",
    "            redLight = True\n",
    "\n",
    "\n",
    "        ###########yellow traffic light detection###########\n",
    "        # define range of orange color in HSV\n",
    "        lower_yellow = np.array([5,150,150]) \n",
    "        upper_yellow = np.array([40,255,255]) #real amber traffic light works 15,255,255])\n",
    "        [clr_ID, yellowImg] = get_light_color(image, imgo, tl_loc, lower_yellow, upper_yellow)\n",
    "        if (clr_ID == \"YELLOW\"):\n",
    "            yellowLight = True\n",
    "            \t\n",
    "        if ((yellowLight == True) and (redLight == False) \n",
    "             and (greenLight == False)):\n",
    "            clr_ID = \"YELLOW\"\n",
    "            result = yellowImg\n",
    "\n",
    "        elif ((yellowLight == False) and (redLight == True) \n",
    "            and (yellowLight == False)):\n",
    "            clr_ID = \"RED\"\n",
    "            result = redImg\n",
    "\n",
    "        elif ((yellowLight == False) and (redLight == False) \n",
    "             and (greenLight == True)):\n",
    "            clr_ID = \"GREEN\" \n",
    "            result = greenImg\n",
    "        else:\n",
    "            clr_ID = \"UNKNOWN\"\n",
    "            result = image\n",
    "        \n",
    "        #plt.imshow(result)\n",
    "        #plt.show()\n",
    "        #print(\"Traffic Light color_ID: {}\".format(clr_ID))\n",
    "    return result        \n",
    "\n",
    "def SSDobjDet(Vin, Vout):\n",
    "    clip1 = VideoFileClip(Vin)\n",
    "    white_clip = clip1.fl_image(process_image)\n",
    "    %time white_clip.write_videofile(Vout, audio=False)\n",
    "    return Vout\n",
    "\n",
    "def videoAnnotate(VideoIn, VideoOut):\n",
    "    HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "    <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(SSDobjDet(VideoIn, VideoOut)\n",
    "        ))  \n",
    "            \n",
    "####main run######\n",
    "#Download frozen model\n",
    "#download_frozen_model()\n",
    "\n",
    "#load the SSD classifier\n",
    "print(\"Loading SSD classifier.\")\n",
    "global detection_graph\n",
    "detection_graph = loadSSD()\n",
    "\"\"\"\n",
    "dir = \"test_images/image\" \n",
    "for i in range(13,23):\n",
    "    FNum = \"\".join([dir, str(i+1)])\n",
    "    FName = \".\".join([FNum, \"jpg\"])\n",
    "    print(\"File name: {}\".format(FName))\n",
    "    plt.imshow(process_image(cv2.cvtColor(cv2.imread(FName), cv2.COLOR_BGR2RGB)))\n",
    "    plt.show()\n",
    "\"\"\"   \n",
    "## produce a video that finds objects ########\n",
    "#videoAnnotate(\"test_videos/MOVI0017_1secto1min31sec.mp4\", \"test_videos/MOVI0017SSD_1secto1min31sec.mp4\")\n",
    "videoAnnotate(\"test_videos/MOVI0017_1min32secto3min2sec.mp4\", \"test_videos/MOVI0017SSD_1min32secto3min2sec.mp4\")\n",
    "#videoAnnotate(\"test_videos/MOVI0019_1secto1min31sec.mp4\", \"test_videos/MOVI0019SSD_1secto1min31sec.mp4\")\n",
    "#videoAnnotate(\"test_videos/MOVI0019_1min32secto3min2sec.mp4\", \"test_videos/MOVI0019SSD_1min32secto3min2sec.mp4\")\n",
    "#videoAnnotate(\"test_videos/MOVI0019_69to79sec.mp4\", \"test_videos/MOVI0019_69to79secSSD.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
